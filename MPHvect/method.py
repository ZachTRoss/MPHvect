# -*- coding: utf-8 -*-
"""method_new (1/21/26).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1caxVyNmpEZLHUWNBm-EMaI-OYlNmX9Cs
"""

import numpy as np
import matplotlib.pyplot as plt
import itertools
#from numba import njit, prange
from sklearn.neighbors import KernelDensity
import plotly.graph_objects as go
import matplotlib.colors as mcolors

#Normalize Signed Barcodes to Fit inside Unit Square, and replace infinite values with 1


def replace_inf_safe(barcode):
    vectors_copy = barcode.copy()

    for arr in vectors_copy:
      arr[np.isinf(arr)] = 1

    return vectors_copy

# Try import numba; if not present, fall back to no-jit
try:
    from numba import njit, prange
    NUMBA_AVAILABLE = True
except Exception:
    def njit(func=None, **kwargs):
        if func is None:
            def _dec(f):
                return f
            return _dec
        return func
    NUMBA_AVAILABLE = False


# ---------------------------
# NUMBA-accelerated internals
# ---------------------------

@njit
def my_lambda(n, p, x):
    return 2.0**n * max(0.0, min(x - p))

@njit
def magn(v):
    s = 0
    for i in range(len(v)):
        s += v[i]
    return s

# Precompute all indexing vectors (same for all n,p,x)


@njit
def make_indexing_vectors(dim):
    n = 1 << dim          # 2**dim
    out = np.empty((n, dim), dtype=np.int64)

    for i in range(n):
        for j in range(dim):
            # fill from most-significant bit to least
            out[i, dim - 1 - j] = (i >> j) & 1

    return out
    


@njit
def partial_kernel(n, p, x):
    total = 0.0
    scale = 2.0**(-n)
    indexing_vectors=make_indexing_vectors(len(p))
    for i in range(indexing_vectors.shape[0]):
        v = indexing_vectors[i]
        index_point = p + scale * v
        total += (-1)**magn(v) * my_lambda(n, index_point, x)
    return total

@njit
def trans_vector(dim_diagrams):
    t = np.empty(dim_diagrams, dtype=np.float64)
    for i in range(dim_diagrams):
        t[i] = 1.0
    return t

@njit
def my_kernel(n, p, x):
    m = np.max(np.abs(p - x))
    if m > 2.0**(-n):
        return 0.0
    else:
        return partial_kernel(n, p - trans_vector(len(p)), x) - partial_kernel(n, p, x)


@njit
def vectorize_fast(n_list, p_list, pers_diagram, multiplicities):
    """
    Compute the kernel embedding vector for a persistence diagram.

    n_list: (N,) array of integers (kernel parameters)
    p_list: (N, d) array of kernel centers
    pers_diagram: (M, d) array of diagram points
    multiplicities: (M,) array of multiplicities

    Returns: (N,) vector = sum_i multiplicities[i] * K(·, x_i)
    """
    N = len(n_list)
    M = pers_diagram.shape[0]
    out = np.zeros(N)
    for i in range(N):
        n = n_list[i]
        p = p_list[i]
        total = 0.0
        for j in range(M):
            total += multiplicities[j] * my_kernel(n, p, pers_diagram[j])
        out[i] = total
    return out

# ---------------------------
# Python fallbacks if numba is unavailable
# ---------------------------

if not NUMBA_AVAILABLE:

   
    def my_lambda(n, p, x):
        return 2.0**n * max(0.0, min(x - p))
    
    
    def magn(v):
        s = 0
        for i in range(len(v)):
            s += v[i]
        return s
    
    
    
    
   
    def partial_kernel(n, p, x):
        total = 0.0
        scale = 2.0**(-n)
        dim_diagrams=len(p)
        indexing_vectors = np.array(list(itertools.product([0, 1], repeat=dim_diagrams)), dtype=np.int64)
        for i in range(indexing_vectors.shape[0]):
            v = indexing_vectors[i]
            index_point = p + scale * v
            total += (-1)**magn(v) * my_lambda(n, index_point, x)
        return total
    
    
    def trans_vector(dim_diagrams):
        t = np.empty(dim_diagrams, dtype=np.float64)
        for i in range(dim_diagrams):
            t[i] = 1.0
        return t
    
    
    def my_kernel(n, p, x):
        m = np.max(np.abs(p - x))
        if m > 2.0**(-n):
            return 0.0
        else:
            return partial_kernel(n, p - trans_vector(len(p)), x) - partial_kernel(n, p, x)
    
    
   
    def vectorize_fast(n_list, p_list, pers_diagram, multiplicities):
        """
        Compute the kernel embedding vector for a persistence diagram.
    
        n_list: (N,) array of integers (kernel parameters)
        p_list: (N, d) array of kernel centers
        pers_diagram: (M, d) array of diagram points
        multiplicities: (M,) array of multiplicities
    
        Returns: (N,) vector = sum_i multiplicities[i] * K(·, x_i)
        """
        N = len(n_list)
        M = pers_diagram.shape[0]
        out = np.zeros(N)
        for i in range(N):
            n = n_list[i]
            p = p_list[i]
            total = 0.0
            for j in range(M):
                total += multiplicities[j] * my_kernel(n, p, pers_diagram[j])
            out[i] = total
        return out


def generate_V_n(dim, n):
    nums = range(0, 2**n + 1)
    V = []

    for point in itertools.product(nums, repeat=2 * dim):
        if all(a % 2 == 0 for a in point):
            continue
        if not all(point[i] < point[i + dim] for i in range(dim)):
            continue

        scaled = tuple(a / (2**n) for a in point)
        V.append(scaled)

    V.sort()
    return np.array(V, dtype=float)


def collect_vertices(dim, max_layer):
    all_n = []
    all_p = []
    for n in range(max_layer + 1):
        Vn = generate_V_n(dim, n)
        for p in Vn:
            all_n.append(n)
            all_p.append(p)
    return np.array(all_n, dtype=np.int64), np.array(all_p, dtype=float)


def generate_mixup_V_n(dim, n):
    nums = range(0, 2**n + 1)
    V = []

    for point in itertools.product(nums, repeat=dim):
        if all(a % 2 == 0 for a in point):
            continue
        if not all(point[i] < point[i + 1] for i in range(dim-1)):
            continue

        scaled = tuple(a / (2**n) for a in point)
        V.append(scaled)

    V.sort()
    return np.array(V, dtype=float)


def collect_vertices_mixup(max_layer):
    all_n = []
    all_p = []
    for n in range(max_layer + 1):
        Vn = generate_mixup_V_n(3, n)
        for p in Vn:
            all_n.append(n)
            all_p.append(p)
    return np.array(all_n, dtype=np.int64), np.array(all_p, dtype=np.float64)
# ---------------------------
# New version of generate_vect_map returning arrays, not lambdas
# ---------------------------




# ---------------------------
# Original vectorization functions
# ---------------------------

def vectorize(index_list, pers_diagram):
    """
    index_list should be (n_list, p_list).
    """
    n_list, p_list = index_list
    out = []
    for n, p in zip(n_list, p_list):
        total = 0.0
        for x in pers_diagram:
            total += my_kernel(n, p, x)
        out.append(total)
    return np.array(out)





# ---------------------------
# One-shot vectorization map
# ---------------------------

def MPHvect_vectorization_map(pers_diagram, multiplicities, dim=2, max_layer=4):
    if not np.all(np.isfinite(pers_diagram)):
        raise ValueError("pers_diagram contains non-finite values")
    if np.any(pers_diagram > 1):
        raise ValueError("pers_diagram entries must be <= 1")

    n_list, p_list = collect_vertices(dim, max_layer)
    return vectorize_fast(n_list, p_list, pers_diagram, multiplicities)

#Visualize this Vectorization on the Signed Barcode

# Number of colors
n_colors = 8

# Choose a colormap (perceptually uniform is best for distinguishing colors)
cmap = plt.get_cmap("YlGnBu")  # you can try "plasma", "cividis", etc.



# Sample the colormap at n_colors evenly spaced points
my_colors = [cmap(i / (n_colors - 1)) for i in range(n_colors)]

# Choose a colormap (perceptually uniform is best for distinguishing colors)
cmap = plt.get_cmap("magma")  # you can try "plasma", "cividis", etc.



# Sample the colormap at n_colors evenly spaced points
my_neg_colors = [cmap(i / (n_colors - 1)) for i in range(n_colors)]




# Plot the colors to visualize

# Print RGBA values for reference
#for i, color in enumerate(colors):
   # print(f"Color {i+1}: {color}")
plotly_colors = [f"rgba({int(r*255)}, {int(g*255)}, {int(b*255)}, {a})"
                 for r, g, b, a in my_colors]

plotly_neg_colors = [f"rgba({int(r*255)}, {int(g*255)}, {int(b*255)}, {a})"
                 for r, g, b, a in my_neg_colors]


def add_quads(fig, quads, color, opacity=0.6):
    """Batch add quads as a single Mesh3d trace (two triangles per quad)."""
    xs, ys, zs = [], [], []
    i, j, k = [], [], []

    for q_idx, corners in enumerate(quads):
        # corners = [a, b, c, d]
        a, b, c, d = corners
        base = 4 * q_idx

        xs.extend([a[0], b[0], c[0], d[0]])
        ys.extend([a[1], b[1], c[1], d[1]])
        zs.extend([a[2], b[2], c[2], d[2]])

        # two triangles: (a,b,c) and (a,c,d)
        i.extend([base, base])
        j.extend([base+1, base+2])
        k.extend([base+2, base+3])

    fig.add_trace(go.Mesh3d(
        x=xs, y=ys, z=zs,
        i=i, j=j, k=k,
        color=color, opacity=opacity,
        flatshading=True,
        showscale=False
    ))

def plot_razor_blades(bars, multiplicities, vectorizations, colors=plotly_colors, neg_colors=plotly_neg_colors):


    fig = go.Figure()

    # Base XY-plane shading
    grid_x = np.linspace(0, 1, 100)
    grid_y = np.linspace(0, 1.25, 100)
    Zg = np.zeros((100,100))
    fig.add_trace(go.Surface(
        x=grid_x, y=grid_y, z=Zg,
        opacity=0.5, showscale=False,
        colorscale="Blues"
    ))

    # Collect quads grouped by color
    pos_quads = {c: [] for c in colors}
    neg_quads = {c: [] for c in neg_colors}

    for i, x in enumerate(bars):
        mult = multiplicities[i]
        vector = vectorizations[i]

        # Base line (red)
        fig.add_trace(go.Scatter3d(
            x=[x[0], x[2]], y=[x[1], x[3]], z=[0,0],
            mode='lines',
            line=dict(color='red', width=3),
            showlegend=False
        ))

        z_start = 0
        for j, length in enumerate(vector):
            z_end = z_start + length
            corners = np.array([
                [x[0], x[1], z_start],
                [x[2], x[3], z_start],
                [x[2], x[3], z_end],
                [x[0], x[1], z_end]
            ])
            if mult >=0:
                pos_quads[colors[j % len(colors)]].append(corners)
            elif mult <=0:
                neg_quads[neg_colors[j % len(neg_colors)]].append(corners)
            z_start = z_end

    # Batch add quads
    for color, quads in pos_quads.items():
        if quads:
            add_quads(fig, quads, color, opacity=0.6)
    for color, quads in neg_quads.items():
        if quads:
            add_quads(fig, quads, color, opacity=0.6)

    # Layout once at the end
    fig.update_layout(
        scene=dict(
            xaxis=dict(range=[0, 0.5], showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(range=[0, 1], showgrid=False, zeroline=False, showticklabels=False),
            zaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        ),
        width=700, height=600,
        margin=dict(l=0, r=0, t=0, b=0),
        showlegend=False
    )

    fig.show()

#This function plots a visualization of the vectorization of a 1-parameter persistence module.
def plot_nailbed(points, vectors, colors=plotly_colors):


    fig = go.Figure()
    vectors=np.array(vectors)
    y_max = max(points[:,1])
    x_min = min(points[:,0])

    # Shaded region x <= y (in XY-plane at z=0)
    grid_x = np.linspace(0-0.25*y_max, y_max, 200)
    grid_y = np.linspace(0-0.25*y_max, y_max, 200)
    Xg, Yg = np.meshgrid(grid_x, grid_y)
    mask = Xg <= Yg
    Zg = np.zeros_like(Xg)

    Xmask = np.where(mask, Xg, np.nan)
    Ymask = np.where(mask, Yg, np.nan)
    Zmask = np.where(mask, Zg, np.nan)

    fig.add_trace(go.Surface(
        x=Xmask, y=Ymask, z=Zmask,
        opacity=0.5, showscale=False,
        colorscale="Blues"
    ))

    # Black boundary line (x=y, z=0)
    line_range = np.linspace(-2, 4, 100)
    fig.add_trace(go.Scatter3d(
        x=line_range, y=line_range, z=np.zeros_like(line_range),
        mode="lines", line=dict(color="black", width=6)
    ))

    # Grouped line segments for stacked vectors
    for j in range(vectors.shape[1]):  # each "layer" index
        xs, ys, zs = [], [], []
        for i, x in enumerate(points):
            Y = vectors[i]
            # compute segment start/end for this layer
            z_start = sum(Y[:j]) if j < len(Y) else None
            z_end = z_start + Y[j] if j < len(Y) else None
            if z_start is not None:
                xs.extend([x[0], x[0], None])
                ys.extend([x[1], x[1], None])
                zs.extend([z_start, z_end, None])

        fig.add_trace(go.Scatter3d(
            x=xs, y=ys, z=zs,
            mode="lines",
            line=dict(color=colors[j % len(colors)], width=6),
            showlegend=False
        ))

    # Red base points
    fig.add_trace(go.Scatter3d(
        x=points[:,0], y=points[:,1], z=np.zeros(points.shape[0]),
        mode="markers", marker=dict(size=3, color="red"),
        name="base points"
    ))

    # Layout cleanup
    fig.update_layout(
        scene=dict(
            xaxis=dict(range=[0.9*x_min, 1*y_max],
                       showgrid=False, zeroline=False, showticklabels=False, showbackground=False, title=''),
            yaxis=dict(range=[0.9*x_min, 1.1*y_max],
                       showgrid=False, zeroline=False, showticklabels=False, showbackground=False, title=''),
            zaxis=dict(range=[0, np.max(vectors.sum(axis=1))+1],
                       showgrid=False, zeroline=False, showticklabels=False, showbackground=False, title=''),
        ),
        width=700, height=600,
        margin=dict(l=0, r=0, t=0, b=0),
        showlegend=False
    )

    fig.show()

# This function is a wrap up of the previous two functions. It is the most user-friendly. You can use this to takeinputs of a persistence diagram (and possibly multiplicities), as well as the number of triangulations you wish to use in your vectorizatoin, and output the visualization for the vectorization of given diagram, whether it's 1-parameter or 2-parameter.  Note: This normalizes persistence diagrams by (10*max entry /9), then replaces infinite values with 1. This way, infinite lifespans still rank more highly than the maximal finite lifespan(s).

def MPHvect_visualize(points, multiplicities=None, number_of_triangulations=5):

  if points[0].size==2:
    vecmap=generate_vect_map(1,number_of_triangulations)
    max_val = max(arr[np.isfinite(arr)].max() for arr in points)
    norm_pd = 0.9*points / max_val

    normalized_diagram=replace_inf_safe(norm_pd)

    list_of_vecs=[]
    for x in normalized_diagram:
      list_of_vecs.append(vectorize(vecmap, np.array([x])))

    plot_nailbed(normalized_diagram, list_of_vecs, plotly_colors)

  elif points[0].size==4:
      if multiplicities is None:
        raise ValueError("If points are 4D, multiplicities must be provided as an np.array of equal length to 'points'.")

      vecmap=generate_vect_map(2,number_of_triangulations)
      max_val = max(arr[np.isfinite(arr)].max() for arr in points)
      norm_pd = 0.9*points / max_val

      normalized_diagram=replace_inf_safe(norm_pd)

      list_of_vecs=[]
      for i,x in enumerate(normalized_diagram):
        list_of_vecs.append(multiplicities[i]*vectorize(vecmap, np.array([x])))
      plot_razor_blades(normalized_diagram, multiplicities, list_of_vecs, colors=plotly_colors, neg_colors=plotly_neg_colors)
  else:
      raise ValueError("Persistent Diagram must consist of points in 2D or 4D")

def plot_mixup(points):
    """
    Plots 3D points in R^3 and the plane y = z as a semi-transparent surface.

    Parameters
    ----------
    points : np.ndarray
        Array of shape (n, 3), where each row is a 3D point [x, y, z].
    """
    if points.ndim != 2 or points.shape[1] != 3:
        raise ValueError("Input must be of shape (n, 3)")

    # Extract coordinates
    x, y, z = points[:, 0], points[:, 1], points[:, 2]

    # Scatter plot of points
    scatter = go.Scatter3d(
        x=x, y=y, z=z,
        mode='markers',
        marker=dict(size=6, color='blue', opacity=0.8),
        name='Points'
    )

    # Define a grid for the plane y = z
    grid_range = np.linspace(min(x.min(), y.min(), z.min()) - 1,
                             max(x.max(), y.max(), z.max()) + 1, 40)
    X, Y = np.meshgrid(grid_range, grid_range)
    Z = Y  # because y = z

    # Plane surface
    plane = go.Surface(
        x=X, y=Y, z=Z,
        colorscale=[[0, 'orange'], [1, 'orange']],
        opacity=0.4,
        showscale=False,
        name='Plane y=z'
    )

    # Combine and configure layout
    fig = go.Figure(data=[scatter, plane])
    fig.update_layout(
        scene=dict(
            xaxis_title='X',
            yaxis_title='Y',
            zaxis_title='Z',
            aspectmode='cube',
        ),
        title='3D Points with Plane y = z',
        template='plotly_white',
    )

    fig.show()

#plot mixup barcode vectorization
def plot_mixup_nailbed(points, vectors, colors=plotly_neg_colors):
    """
    Plots 3D points in R^3 and draws stacked, multicolored line segments
    perpendicular to the plane y=z (i.e., parallel to [0, -1, 1]).

    Parameters
    ----------
    points : np.ndarray
        Array of shape (n, 3), base points in R^3.
    vectors : np.ndarray
        Array of shape (n, m), segment lengths for each base point.
    colors : list of str, optional
        Colors for each segment "layer".
    """
    if colors is None:
        colors = ["blue", "green", "orange", "purple"]

    points = np.array(points)
    vectors = np.array(vectors)
    if points.shape[1] != 3:
        raise ValueError("points must have shape (n, 3)")

    fig = go.Figure()

    # ---- 1. Plot the semi-transparent plane y=z ----
    # Determine data range
    all_coords = points.flatten()
    coord_min, coord_max = np.min(all_coords) - 1, np.max(all_coords) + 1

    X, Y = np.meshgrid(
        np.linspace(coord_min, coord_max, 30),
        np.linspace(coord_min, coord_max, 30)
    )
    Z = Y  # y=z

    fig.add_trace(go.Surface(
        x=X, y=Y, z=Z,
        colorscale=[[0, 'orange'], [1, 'orange']],
        opacity=0.35,
        showscale=False,
        name="Plane y=z"
    ))

    # ---- 2. Draw multicolored "nails" along direction [0, -1, 1] ----
    direction = np.array([0, -1, 1])
    direction = direction / np.linalg.norm(direction)  # normalize

    for j in range(vectors.shape[1]):  # segment "layer"
        xs, ys, zs = [], [], []
        for i, base in enumerate(points):
            Y = vectors[i]
            # compute cumulative positions along [0, -1, 1]
            seg_start = base + direction * np.sum(Y[:j]) if j < len(Y) else None
            seg_end = seg_start + direction * Y[j] if j < len(Y) else None
            if seg_start is not None:
                xs.extend([seg_start[0], seg_end[0], None])
                ys.extend([seg_start[1], seg_end[1], None])
                zs.extend([seg_start[2], seg_end[2], None])

        fig.add_trace(go.Scatter3d(
            x=xs, y=ys, z=zs,
            mode="lines",
            line=dict(color=colors[j % len(colors)], width=6),
            showlegend=False
        ))

    # ---- 3. Plot the base points ----
    fig.add_trace(go.Scatter3d(
        x=points[:, 0],
        y=points[:, 1],
        z=points[:, 2],
        mode="markers",
        marker=dict(size=4, color="red"),
        name="Base Points"
    ))

    # ---- 4. Layout configuration ----
    fig.update_layout(
        scene=dict(
            xaxis=dict(range=[0, coord_max],
                       showgrid=False, zeroline=False, showticklabels=False, showbackground=False, title=''),
            yaxis=dict(range=[0,coord_max],
                       showgrid=False, zeroline=False, showticklabels=False, showbackground=False, title=''),
            zaxis=dict(range=[0, coord_max],
                       showgrid=False, zeroline=False, showticklabels=False, showbackground=False, title=''),
        ),
        width=700, height=600,
        margin=dict(l=0, r=0, t=0, b=0),
        showlegend=False
    )
   #
    fig.show()

from sklearn import svm
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.model_selection import cross_val_score, KFold
#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, 

#define SVM+PCA as a single function to make things easier when doing classifications in the examples
def do_SVM_and_PCA(list1, list2, n_permutations=10, cv_folds=10, random_state=42):
    """
    Performs SVM classification between two sets of vectors, calculates a p-value
    via permutation test, and plots 3D PCA projection.

    Parameters:
    - list1, list2: lists or arrays of vectors (shape: n_samples x n_features)
    - n_permutations: number of permutations for p-value calculation
    - cv_folds: number of cross-validation folds (default 10)
    - random_state: random seed for reproducibility

    Returns:
    - accuracy: SVM cross-validated accuracy
    - p_value: permutation test p-value
    """
    np.random.seed(random_state)

    # Convert lists to arrays
    X1 = np.array(list1)
    X2 = np.array(list2)

    # Combine data and labels
    X = np.vstack([X1, X2])
    y = np.array([0]*len(X1) + [1]*len(X2))

    # Define cross-validation strategy
    cv = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)

    # Train SVM and calculate cross-validated accuracy
    clf = SVC(kernel='linear')
    accuracy = np.mean(cross_val_score(clf, X, y, cv=cv))
    print(accuracy)
    # Permutation test for p-value
    perm_accuracies = []
    for _ in range(n_permutations):
        y_perm = np.random.permutation(y)
        perm_acc = np.mean(cross_val_score(clf, X, y_perm, cv=cv))
        perm_accuracies.append(perm_acc)
    perm_accuracies = np.array(perm_accuracies)
    p_value = np.mean(perm_accuracies >= accuracy)
    print(p_value)
    # PCA for visualization
    pca = PCA(n_components=3)
    X_pca = pca.fit_transform(X)

    fig = plt.figure(figsize=(8,6))
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(X_pca[y==0,0], X_pca[y==0,1], X_pca[y==0,2], c='r', label='Class 0', s=50)
    ax.scatter(X_pca[y==1,0], X_pca[y==1,1], X_pca[y==1,2], c='b', label='Class 1', s=50)
    ax.set_xlabel('PC1')
    ax.set_ylabel('PC2')
    ax.set_zlabel('PC3')
    ax.set_title(f'3D PCA Projection (SVM Acc={accuracy:.2f}, p={p_value:.3f})')
    ax.legend()
    plt.show()
